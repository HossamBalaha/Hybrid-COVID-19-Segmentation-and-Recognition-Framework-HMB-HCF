{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Hybrid COVID-19 Segmentation and Recognition Framework (HMB-HCF) using Deep Learning and Genetic Algorithms.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.9"
    },
    "latex_envs": {
      "LaTeX_envs_menu_present": true,
      "autoclose": false,
      "autocomplete": true,
      "bibliofile": "biblio.bib",
      "cite_by": "apalike",
      "current_citInitial": 1,
      "eqLabelWithNumbers": true,
      "eqNumInitial": 1,
      "hotkeys": {
        "equation": "Ctrl-E",
        "itemize": "Ctrl-I"
      },
      "labels_anchors": false,
      "latex_user_defs": false,
      "report_style_numbering": false,
      "user_envs_cfg": false
    },
    "notify_time": "5",
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": true,
      "toc_position": {
        "height": "calc(100% - 180px)",
        "left": "10px",
        "top": "150px",
        "width": "320px"
      },
      "toc_section_display": true,
      "toc_window_display": true
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "oldHeight": 198.316666,
      "position": {
        "height": "40px",
        "left": "1096.53px",
        "right": "20px",
        "top": "120px",
        "width": "355.467px"
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "varInspector_section_display": "none",
      "window_display": false
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-01-28T18:14:54.182548Z",
          "start_time": "2021-01-28T18:14:54.168543Z"
        },
        "id": "d6zMjxTcc4Bu"
      },
      "source": [
        "TF_VERSION = \"2.1.0\"\n",
        "DEBUG = True\n",
        "COLAB = True\n",
        "BASE_DIR = os.getcwd()\n",
        "COLAB_DIR = \"/content/drive/MyDrive/\"\n",
        "\n",
        "if COLAB:\n",
        "  BASE_DIR = COLAB_DIR\n",
        "  from google.colab import drive\n",
        "  drive.mount(\"/content/drive\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-01-28T18:14:54.213531Z",
          "start_time": "2021-01-28T18:14:54.184532Z"
        },
        "id": "AeusxWB3c015"
      },
      "source": [
        "from abc import ABCMeta, abstractmethod\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2, os, itertools, random, pickle, warnings, datetime, math, gc, copy\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras import layers, models, applications, callbacks, metrics\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import LeakyReLU, PReLU\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.regularizers import L1L2, l2, l1, l1_l2\n",
        "from tensorflow.keras.models import load_model"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-01-28T18:14:54.291471Z",
          "start_time": "2021-01-28T18:14:54.215530Z"
        },
        "code_folding": [
          0,
          6,
          11,
          19,
          63,
          92,
          115,
          125,
          136,
          159,
          165,
          171,
          176,
          237
        ],
        "hidden": true,
        "id": "86nJeb2Gc02E"
      },
      "source": [
        "def LoadWorkState(statePickle):\n",
        "  f = open(statePickle, \"rb\")\n",
        "  L = pickle.load(f)\n",
        "  f.close()\n",
        "  return L\n",
        "\n",
        "\n",
        "def StoreWorkState(L, statePickle):\n",
        "  f = open(statePickle, \"wb\")\n",
        "  L = pickle.dump(L, f)\n",
        "  f.close()\n",
        "\n",
        "\n",
        "def GetCurrentState():\n",
        "  L = {\n",
        "    \"TF_VERSION\": TF_VERSION,\n",
        "    \"DEBUG\": DEBUG,\n",
        "    \"COLAB\": COLAB,\n",
        "    \"BASE_DIR\": BASE_DIR,\n",
        "    \"COLAB_DIR\": COLAB_DIR,\n",
        "    \"OWNER\": OWNER,\n",
        "    \"PBO\": PBO,\n",
        "    \"MODEL\": MODEL,\n",
        "    \"DATASET_PICKLE_FILE\": DATASET_PICKLE_FILE,\n",
        "    \"PICKELS_BASE_DIR\": PICKELS_BASE_DIR,\n",
        "    \"RESULTS_BASE_DIR\": RESULTS_BASE_DIR,\n",
        "    \"IMAGE_SHAPE\": IMAGE_SHAPE,\n",
        "    \"CATEGORIES\": CATEGORIES,\n",
        "    \"ITERS\": ITERS,\n",
        "    \"EPOCHS\": EPOCHS,\n",
        "    \"POPULATION_SIZE\": POPULATION_SIZE,\n",
        "    \"DIM\": DIM,\n",
        "    \"SKIP\": SKIP,\n",
        "    \"POPULATION\": POPULATION,\n",
        "    \"IS_NEW\": IS_NEW,\n",
        "    \"TRAIN_RATIO\": TRAIN_RATIO,\n",
        "    \"DROPOUT_RANGE\": DROPOUT_RANGE,\n",
        "    \"OUTPUT_ACTIVATION\": OUTPUT_ACTIVATION,\n",
        "    \"PRETRAINED_WEIGHTS\": PRETRAINED_WEIGHTS,\n",
        "    \"BATCH_SIZES\": BATCH_SIZES,\n",
        "    \"LEARN_RATIOS\": LEARN_RATIOS,\n",
        "    \"OPTIMIZERS\": OPTIMIZERS,\n",
        "    \"HIDDEN_ACTIVATIONS\": HIDDEN_ACTIVATIONS,\n",
        "    \"WEIGHT_INITIALIZERS\": WEIGHT_INITIALIZERS,\n",
        "    \"RESULTS_DIR\": RESULTS_DIR,\n",
        "    \"DATASET_PICKLE\": DATASET_PICKLE,\n",
        "    \"OWNER_DIR\": OWNER_DIR,\n",
        "    \"HDF5_RESULTS_DIR\": HDF5_RESULTS_DIR,\n",
        "    \"FIGURES_RESULTS_DIR\": FIGURES_RESULTS_DIR,\n",
        "    \"HISTORY_RESULTS_DIR\": HISTORY_RESULTS_DIR,\n",
        "    \"STATE_PICKLE\": STATE_PICKLE,\n",
        "    \"LOGGER_FILE\": LOGGER_FILE,\n",
        "    \"BEST_FILE\": BEST_FILE,\n",
        "    \"SPLIT_DATASET_PICKLE\": SPLIT_DATASET_PICKLE,\n",
        "    \"AUGMENTATION_CONFIG\": AUGMENTATION_CONFIG,\n",
        "    \"GA\": {},\n",
        "    \"INTERPOLATION\": INTERPOLATION,\n",
        "    \"USE_TF\": USE_TF,\n",
        "    \"REGULARIZERS\": REGULARIZERS,\n",
        "  }\n",
        "  return L\n",
        "\n",
        "\n",
        "def LoadCreateSplitFile(datasetPickle,\n",
        "            splitPickle,\n",
        "            noOfClasses,\n",
        "            trainRatio,\n",
        "            debug=True):\n",
        "  if (os.path.exists(splitPickle)):\n",
        "    f = open(splitPickle, \"rb\")\n",
        "    [Xtrain, Xvalidation, Xtest, Ytrain, Yvalidation,\n",
        "     Ytest] = pickle.load(f)\n",
        "    f.close()\n",
        "    Q = [Xtrain, Xvalidation, Xtest, Ytrain, Yvalidation, Ytest]\n",
        "  else:\n",
        "    randomState = 42\n",
        "    f = open(datasetPickle, \"rb\")\n",
        "    dataset = pickle.load(f)\n",
        "    f.close()\n",
        "    random.shuffle(dataset)\n",
        "    images, classes = zip(*dataset)\n",
        "    images = np.array(images, dtype='float32')\n",
        "    images = (images / 255.0).astype('float32')\n",
        "    classes = to_categorical(classes, noOfClasses)\n",
        "    classes = np.array(classes)\n",
        "    Xtrain, Xtest, Ytrain, Ytest = train_test_split(\n",
        "      images, classes, train_size=trainRatio, random_state=randomState)\n",
        "    Xtrain, Xvalidation, Ytrain, Yvalidation = train_test_split(\n",
        "      Xtrain, Ytrain, train_size=trainRatio, random_state=randomState)\n",
        "    Q = [Xtrain, Xvalidation, Xtest, Ytrain, Yvalidation, Ytest]\n",
        "    f = open(splitPickle, \"wb\")\n",
        "    pickle.dump(Q, f)\n",
        "    f.close()\n",
        "  return Q\n",
        "\n",
        "\n",
        "def HandleCurrentState(isNew, statePickle, loggerFile):\n",
        "  if (isNew):\n",
        "    currentState = GetCurrentState()\n",
        "    StoreWorkState(currentState, statePickle)\n",
        "  else:\n",
        "    if (os.path.exists(statePickle)):\n",
        "      currentState = LoadWorkState(statePickle)\n",
        "    else:\n",
        "      currentState = GetCurrentState()\n",
        "      StoreWorkState(currentState, statePickle)\n",
        "  return currentState\n",
        "\n",
        "\n",
        "def recall_m(yTrue, yPred):\n",
        "  truePositives = K.sum(K.round(K.clip(yTrue * yPred, 0, 1)))\n",
        "  possiblePositives = K.sum(K.round(K.clip(yTrue, 0, 1)))\n",
        "  recall = truePositives / (possiblePositives + K.epsilon())\n",
        "  return recall\n",
        "\n",
        "\n",
        "def precision_m(yTrue, yPred):\n",
        "  truePositives = K.sum(K.round(K.clip(yTrue * yPred, 0, 1)))\n",
        "  predictedPositives = K.sum(K.round(K.clip(yPred, 0, 1)))\n",
        "  precision = truePositives / (predictedPositives + K.epsilon())\n",
        "  return precision\n",
        "\n",
        "\n",
        "def f1_m(yTrue, yPred):\n",
        "  precision = precision_m(yTrue, yPred)\n",
        "  recall = recall_m(yTrue, yPred)\n",
        "  return 2.0 * ((precision * recall) / (precision + recall + K.epsilon()))\n",
        "\n",
        "\n",
        "def BuildCompileTransferLearningCNN(model,\n",
        "                  inputShape,\n",
        "                  noOfClasses,\n",
        "                  hiddenActivation,\n",
        "                  outputActivation,\n",
        "                  weightInitializer,\n",
        "                  pretrainedWeights,\n",
        "                  optimizer,\n",
        "                  dropout,\n",
        "                  learnRatio,\n",
        "                  regularizer,\n",
        "                  debug=True):\n",
        "\n",
        "  baseModel = None\n",
        "  includeTop = False\n",
        "\n",
        "  if (model == \"MobileNetV2\"):\n",
        "    baseModel = applications.MobileNetV2(weights=pretrainedWeights,\n",
        "                       include_top=includeTop)\n",
        "  elif (model == \"MobileNet\"):\n",
        "    baseModel = applications.MobileNet(weights=pretrainedWeights,\n",
        "                       include_top=includeTop)\n",
        "  elif (model == \"VGG16\"):\n",
        "    baseModel = applications.VGG16(weights=pretrainedWeights,\n",
        "                     include_top=includeTop)\n",
        "  elif (model == \"VGG19\"):\n",
        "    baseModel = applications.VGG19(weights=pretrainedWeights,\n",
        "                     include_top=includeTop)\n",
        "  elif (model == \"ResNet50\"):\n",
        "    baseModel = applications.ResNet50(weights=pretrainedWeights,\n",
        "                      include_top=includeTop)\n",
        "  elif (model == \"ResNet101\"):\n",
        "    baseModel = applications.ResNet101(weights=pretrainedWeights,\n",
        "                       include_top=includeTop)\n",
        "  elif (model == \"Xception\"):\n",
        "    baseModel = applications.Xception(weights=pretrainedWeights,\n",
        "                      include_top=includeTop)\n",
        "  elif (model == \"DenseNet121\"):\n",
        "    baseModel = applications.DenseNet121(weights=pretrainedWeights,\n",
        "                       include_top=includeTop)\n",
        "  elif (model == \"DenseNet169\"):\n",
        "    baseModel = applications.DenseNet169(weights=pretrainedWeights,\n",
        "                       include_top=includeTop)\n",
        "\n",
        "  if (learnRatio is None): learnRatio = 100.0\n",
        "\n",
        "  for layer in baseModel.layers:\n",
        "    layer.trainable = False\n",
        "  L = len(baseModel.layers)\n",
        "  fromL = int(learnRatio * L / 100.0)\n",
        "  for layer in baseModel.layers[L - fromL:]:\n",
        "    layer.trainable = True\n",
        "\n",
        "  if (dropout is None or dropout <= 0):\n",
        "    model = tf.keras.Sequential([\n",
        "      baseModel,\n",
        "      layers.GlobalAveragePooling2D(),\n",
        "      layers.Dense(noOfClasses, activation=outputActivation)\n",
        "    ])\n",
        "  else:\n",
        "    model = tf.keras.Sequential([\n",
        "      baseModel,\n",
        "      layers.GlobalAveragePooling2D(),\n",
        "      layers.Dropout(dropout),\n",
        "      layers.Dense(noOfClasses, activation=outputActivation)\n",
        "    ])\n",
        "\n",
        "  metricsList = [\n",
        "    'accuracy', f1_m, precision_m, recall_m,\n",
        "    metrics.AUC(),\n",
        "    metrics.Precision(),\n",
        "    metrics.Recall()\n",
        "  ]\n",
        "  loss = \"categorical_crossentropy\"\n",
        "  if (optimizer is not None):\n",
        "    model.compile(optimizer=optimizer, loss=loss, metrics=metricsList)\n",
        "  else:\n",
        "    model.compile(loss=loss, metrics=metricsList)\n",
        "  return model\n",
        "\n",
        "\n",
        "def BuildCompileNativeCNN(model,\n",
        "              inputShape,\n",
        "              noOfClasses,\n",
        "              hiddenActivation,\n",
        "              outputActivation,\n",
        "              weightInitializer,\n",
        "              pretrainedWeights,\n",
        "              optimizer,\n",
        "              dropout,\n",
        "              learnRatio,\n",
        "              regularizer,\n",
        "              debug=True):\n",
        "\n",
        "  baseModel = None\n",
        "\n",
        "  def __generateConv2D(noOfFilters,\n",
        "             kernelSize,\n",
        "             strideSize,\n",
        "             hiddenActivation,\n",
        "             weightInitializer,\n",
        "             regularizer,\n",
        "             inputShape=None):\n",
        "    if (weightInitializer is None): weightInitializer = \"glorot_uniform\"\n",
        "    if (inputShape is None):\n",
        "      return layers.Conv2D(noOfFilters,\n",
        "                 kernel_size=kernelSize,\n",
        "                 strides=strideSize,\n",
        "                 padding='same',\n",
        "                 activation=hiddenActivation,\n",
        "                 kernel_initializer=weightInitializer,\n",
        "                 kernel_regularizer=regularizer)\n",
        "    else:\n",
        "      return layers.Conv2D(noOfFilters,\n",
        "                 kernel_size=kernelSize,\n",
        "                 strides=strideSize,\n",
        "                 padding='same',\n",
        "                 activation=hiddenActivation,\n",
        "                 kernel_initializer=weightInitializer,\n",
        "                 kernel_regularizer=regularizer,\n",
        "                 input_shape=inputShape)\n",
        "\n",
        "  if (model == \"HMB1-COVID19\"):\n",
        "    baseModel = tf.keras.Sequential()\n",
        "    for i, k in enumerate([32, 64, 128]):\n",
        "      if (i == 0):\n",
        "        baseModel.add(\n",
        "          __generateConv2D(k, (3, 3), (1, 1), hiddenActivation,\n",
        "                   weightInitializer, regularizer,\n",
        "                   inputShape))\n",
        "      else:\n",
        "        baseModel.add(\n",
        "          __generateConv2D(k, (3, 3), (1, 1), hiddenActivation,\n",
        "                   weightInitializer, regularizer, None))\n",
        "      baseModel.add(layers.BatchNormalization())\n",
        "      baseModel.add(\n",
        "        __generateConv2D(k, (3, 3), (1, 1), hiddenActivation,\n",
        "                 weightInitializer, regularizer))\n",
        "      baseModel.add(layers.BatchNormalization())\n",
        "      baseModel.add(layers.MaxPooling2D(pool_size=2))\n",
        "      if (dropout is not None and dropout > 0):\n",
        "        baseModel.add(layers.Dropout(dropout))\n",
        "\n",
        "    baseModel.add(layers.Flatten())\n",
        "\n",
        "  if (learnRatio is None): learnRatio = 100.0\n",
        "\n",
        "  for layer in baseModel.layers:\n",
        "    layer.trainable = False\n",
        "  L = len(baseModel.layers)\n",
        "  fromL = int(learnRatio * L / 100.0)\n",
        "  for layer in baseModel.layers[L - fromL:]:\n",
        "    layer.trainable = True\n",
        "\n",
        "  model = tf.keras.Sequential(\n",
        "    [baseModel,\n",
        "     layers.Dense(noOfClasses, activation=outputActivation)])\n",
        "\n",
        "  metricsList = [\n",
        "    'accuracy', f1_m, precision_m, recall_m,\n",
        "    metrics.AUC(),\n",
        "    metrics.Precision(),\n",
        "    metrics.Recall()\n",
        "  ]\n",
        "  loss = \"categorical_crossentropy\"\n",
        "  if (optimizer is not None):\n",
        "    model.compile(optimizer=optimizer, loss=loss, metrics=metricsList)\n",
        "  else:\n",
        "    model.compile(loss=loss, metrics=metricsList)\n",
        "  return model\n",
        "\n",
        "\n",
        "def MapSolutionAsString(currentState, solution):\n",
        "  mappedSolution = None\n",
        "  if (isinstance(currentState[\"DIM\"], int)):\n",
        "    mappedSolution = [None, None, None, None, None, None, None]\n",
        "    for i in range(currentState[\"DIM\"]):\n",
        "      mappedSolution[i] = \"auto\"\n",
        "  elif (isinstance(currentState[\"DIM\"], list)\n",
        "      or isinstance(currentState[\"DIM\"], tuple)):\n",
        "    mappedSolution = copy.copy(currentState[\"DIM\"])\n",
        "    for i in range(len(mappedSolution)):\n",
        "      if (mappedSolution[i] == \"N/A\"): mappedSolution[i] = None\n",
        "  if (mappedSolution[0] == \"auto\"):\n",
        "    r1 = math.floor(solution[0] * (len(currentState[\"OPTIMIZERS\"]) - 1))\n",
        "    optimizer = currentState[\"OPTIMIZERS\"][r1]\n",
        "    mappedSolution[0] = optimizer\n",
        "  if (mappedSolution[1] == \"auto\"):\n",
        "    r2 = math.floor(solution[1] * (len(currentState[\"BATCH_SIZES\"]) - 1))\n",
        "    batchSize = currentState[\"BATCH_SIZES\"][r2]\n",
        "    mappedSolution[1] = batchSize\n",
        "  if (mappedSolution[2] == \"auto\"):\n",
        "    low = currentState[\"DROPOUT_RANGE\"][0]\n",
        "    high = currentState[\"DROPOUT_RANGE\"][1]\n",
        "    delta = high - low\n",
        "    dropout = round(solution[2] * delta * 10.0) / 100.0\n",
        "    mappedSolution[2] = dropout\n",
        "  if (mappedSolution[3] == \"auto\"):\n",
        "    r3 = math.floor(solution[3] * (len(currentState[\"LEARN_RATIOS\"]) - 1))\n",
        "    learnRatio = currentState[\"LEARN_RATIOS\"][r3]\n",
        "    mappedSolution[3] = learnRatio\n",
        "  if (mappedSolution[4] == \"auto\"):\n",
        "    r4 = math.floor(solution[4] *\n",
        "            (len(currentState[\"HIDDEN_ACTIVATIONS\"]) - 1))\n",
        "    activation = currentState[\"HIDDEN_ACTIVATIONS\"][r4]\n",
        "    mappedSolution[4] = activation\n",
        "  if (mappedSolution[5] == \"auto\"):\n",
        "    r5 = math.floor(solution[5] *\n",
        "            (len(currentState[\"WEIGHT_INITIALIZERS\"]) - 1))\n",
        "    weightInitializer = currentState[\"WEIGHT_INITIALIZERS\"][r5]\n",
        "    mappedSolution[5] = weightInitializer\n",
        "  if (mappedSolution[6] == \"auto\"):\n",
        "    r6 = math.floor(solution[6] * (len(currentState[\"REGULARIZERS\"]) - 1))\n",
        "    regularizer = currentState[\"REGULARIZERS\"][r6]\n",
        "    mappedSolution[6] = regularizer\n",
        "  return copy.copy(mappedSolution)\n",
        "\n",
        "\n",
        "def MapSolutionForCNN(currentState, solution):\n",
        "  mappedSolution = MapSolutionAsString(currentState, solution)\n",
        "\n",
        "  if (mappedSolution[4] == \"prelu\"):\n",
        "    activation = PReLU()\n",
        "  elif (mappedSolution[4] == \"leakyrelu\"):\n",
        "    activation = LeakyReLU()\n",
        "\n",
        "  if (mappedSolution[6] is not None):\n",
        "    splitted = mappedSolution[6].split(\"_\")\n",
        "    if (splitted[0] == \"l1\"): regularizer = l1(float(splitted[1]))\n",
        "    elif (splitted[0] == \"l2\"): regularizer = l2(float(splitted[1]))\n",
        "    else: regularizer = None\n",
        "    mappedSolution[6] = regularizer\n",
        "\n",
        "  return copy.copy(mappedSolution)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-01-28T18:14:54.666626Z",
          "start_time": "2021-01-28T18:14:54.293470Z"
        },
        "code_folding": [
          0,
          3
        ],
        "hidden": true,
        "id": "lXiEQF_Qc02S"
      },
      "source": [
        "def FitnessFunction(iteration, solution, currentState):\n",
        "  K.clear_session()\n",
        "  np.random.seed(42)\n",
        "  tf.random.set_seed(42)\n",
        "  gc.collect()\n",
        "\n",
        "  mappedSolution = MapSolutionForCNN(currentState, solution)\n",
        "  optimizer, batchSize, dropout, learnRatio, hiddenActivation, weightInitializer, regularizer = mappedSolution\n",
        "\n",
        "  aug = ImageDataGenerator(\n",
        "    rotation_range=currentState[\"AUGMENTATION_CONFIG\"]['rotation_range'],\n",
        "    width_shift_range=currentState[\"AUGMENTATION_CONFIG\"]\n",
        "    ['width_shift_range'],\n",
        "    height_shift_range=currentState[\"AUGMENTATION_CONFIG\"]\n",
        "    ['height_shift_range'],\n",
        "    shear_range=currentState[\"AUGMENTATION_CONFIG\"]['shear_range'],\n",
        "    zoom_range=currentState[\"AUGMENTATION_CONFIG\"]['zoom_range'],\n",
        "    horizontal_flip=currentState[\"AUGMENTATION_CONFIG\"]['horizontal_flip'],\n",
        "    vertical_flip=currentState[\"AUGMENTATION_CONFIG\"]['vertical_flip'],\n",
        "    fill_mode=currentState[\"AUGMENTATION_CONFIG\"]['fill_mode'],\n",
        "  )\n",
        "\n",
        "  trainIter = aug.flow(Xtrain, Ytrain, batch_size=batchSize)\n",
        "  owner = currentState[\"OWNER\"]\n",
        "  modelName = currentState[\"MODEL\"]\n",
        "  inputShape = currentState[\"IMAGE_SHAPE\"]\n",
        "  noOfClasses = len(currentState[\"CATEGORIES\"])\n",
        "\n",
        "  if (isinstance(optimizer, LeakyReLU) or isinstance(optimizer, PReLU)):\n",
        "    optimizerStr = \"\".join(optimizer.get_config()['name'].split(\"_\")[:3])\n",
        "  else:\n",
        "    optimizerStr = str(optimizer)\n",
        "\n",
        "  if (isinstance(regularizer, L1L2)):\n",
        "    if (regularizer.get_config()['l1'] and regularizer.get_config()['l2']):\n",
        "      egularizerStr = \"l1l2\"\n",
        "    elif (regularizer.get_config()['l1']):\n",
        "      regularizerStr = \"l1\"\n",
        "    elif (regularizer.get_config()['l2']):\n",
        "      regularizerStr = \"l2\"\n",
        "    else:\n",
        "      regularizerStr = \"nan\"\n",
        "  else:\n",
        "    regularizerStr = str(regularizer)\n",
        "\n",
        "  temp1 = f\"{str(owner)}_{str(modelName)}_{str(inputShape)}_{str(noOfClasses)}\"\n",
        "  temp1 += f\"_{optimizerStr}_{str(batchSize)}_{str(dropout)}_{str(learnRatio)}\"\n",
        "  temp1 += f\"_{str(hiddenActivation)}_{str(weightInitializer)}_{str(regularizerStr)}\"\n",
        "  temp2 = temp1 + f\"_{str(iteration)}\"\n",
        "\n",
        "  name1 = f\"{temp1}.hdf5\"\n",
        "  name2 = f\"{temp2}.hdf5\"\n",
        "  figName = f\"{temp2}.jpg\"\n",
        "  csvName = f\"{temp1}.csv\"\n",
        "\n",
        "  checkpointFilepath1 = os.path.join(currentState[\"HDF5_RESULTS_DIR\"], name1)\n",
        "  checkpointFilepath2 = os.path.join(currentState[\"HDF5_RESULTS_DIR\"], name2)\n",
        "  figPath = os.path.join(currentState[\"FIGURES_RESULTS_DIR\"], figName)\n",
        "  csvPath = os.path.join(currentState[\"HISTORY_RESULTS_DIR\"], csvName)\n",
        "\n",
        "  modelCheckpointCallback1 = callbacks.ModelCheckpoint(\n",
        "    filepath=checkpointFilepath1,\n",
        "    monitor='val_accuracy',\n",
        "    mode='max',\n",
        "    save_best_only=True,\n",
        "    verbose=0)\n",
        "  csvLoggerCallback = callbacks.CSVLogger(csvPath, append=True)\n",
        "  earlyStoppingCallback = callbacks.EarlyStopping(monitor='loss', patience=3)\n",
        "  callbacksList = [\n",
        "    modelCheckpointCallback1, csvLoggerCallback, earlyStoppingCallback\n",
        "  ]\n",
        "\n",
        "  toLog = f\"New {temp1}.\"\n",
        "  if (os.path.exists(checkpointFilepath1)):\n",
        "    toLog = f\"Updating using {temp1}.\"\n",
        "    objs = {'f1_m': f1_m, 'precision_m': precision_m, 'recall_m': recall_m}\n",
        "    model = load_model(checkpointFilepath1, custom_objects=objs)\n",
        "    ev = model.evaluate(Xvalidation, Yvalidation, verbose=0)\n",
        "    modelCheckpointCallback1.best = ev[1]\n",
        "    message = f\"Start the Model Checkpoint with a Best Value of {ev[1]}.\"\n",
        "  else:\n",
        "    ev = modelCheckpointCallback1.best\n",
        "    message = f\"Start the Model Checkpoint with a Best Value of {ev}.\"\n",
        "    if (currentState[\"USE_TF\"]):\n",
        "      model = BuildCompileTransferLearningCNN(\n",
        "        modelName,\n",
        "        inputShape,\n",
        "        noOfClasses,\n",
        "        hiddenActivation,\n",
        "        currentState[\"OUTPUT_ACTIVATION\"],\n",
        "        weightInitializer,\n",
        "        currentState[\"PRETRAINED_WEIGHTS\"],\n",
        "        optimizer,\n",
        "        dropout,\n",
        "        learnRatio,\n",
        "        regularizer,\n",
        "        debug=currentState[\"DEBUG\"])\n",
        "    else:\n",
        "      model = BuildCompileNativeCNN(modelName,\n",
        "                      inputShape,\n",
        "                      noOfClasses,\n",
        "                      hiddenActivation,\n",
        "                      currentState[\"OUTPUT_ACTIVATION\"],\n",
        "                      weightInitializer,\n",
        "                      currentState[\"PRETRAINED_WEIGHTS\"],\n",
        "                      optimizer,\n",
        "                      dropout,\n",
        "                      learnRatio,\n",
        "                      regularizer,\n",
        "                      debug=currentState[\"DEBUG\"])\n",
        "\n",
        "  history = model.fit(trainIter,\n",
        "            epochs=currentState[\"EPOCHS\"],\n",
        "            shuffle=True,\n",
        "            validation_data=(Xvalidation, Yvalidation),\n",
        "            callbacks=callbacksList,\n",
        "            verbose=0)\n",
        "\n",
        "  results = model.evaluate(Xtrain, Ytrain, verbose=0)\n",
        "  first = copy.copy(results[:6])\n",
        "  fitnessValueTrain = 0.1 * (1.0 / results[0]) + 0.5 * (results[1] * 100.0) + \\\n",
        "    0.1 * (results[2] * 100.0) + 0.1 * (results[3] * 100.0) + \\\n",
        "    0.1 * (results[4] * 100.0) + 0.1 * (results[5] * 100.0)\n",
        "  results = model.evaluate(Xvalidation, Yvalidation, verbose=0)\n",
        "  second = copy.copy(results[:6])\n",
        "  fitnessValueVal = 0.1 * (1.0 / results[0]) + 0.5 * (results[1] * 100.0) + \\\n",
        "    0.1 * (results[2] * 100.0) + 0.1 * (results[3] * 100.0) + \\\n",
        "    0.1 * (results[4] * 100.0) + 0.1 * (results[5] * 100.0)\n",
        "  results = model.evaluate(Xtest, Ytest, verbose=0)\n",
        "  third = copy.copy(results[:6])\n",
        "  fitnessValueTest = 0.1 * (1.0 / results[0]) + 0.5 * (results[1] * 100.0) + \\\n",
        "    0.1 * (results[2] * 100.0) + 0.1 * (results[3] * 100.0) + \\\n",
        "    0.1 * (results[4] * 100.0) + 0.1 * (results[5] * 100.0)\n",
        "  totalFitnessValue = (fitnessValueTrain + fitnessValueVal +\n",
        "             fitnessValueTest) / 3.0\n",
        "  fitnessValue = np.round(totalFitnessValue, 5)\n",
        "\n",
        "  record = [0, 0, 0, 0, 0, 0, 0]\n",
        "  for q in range(6):\n",
        "    record[q] = float((first[q] + second[q] + third[q]) / 3.0)\n",
        "    if (q in [0, 2, 5]):\n",
        "      if (record[q] >= 100): record[q] = round(record[q], 1)\n",
        "      elif (record[q] >= 10): record[q] = round(record[q], 2)\n",
        "      elif (record[q] >= 1): record[q] = round(record[q], 3)\n",
        "      else: record[q] = round(record[q], 4)\n",
        "    else:\n",
        "      record[q] = round(record[q] * 100.0, 2)\n",
        "  if (fitnessValue >= 100): record[-1] = 100\n",
        "  elif (fitnessValue >= 10): record[-1] = round(fitnessValue, 2)\n",
        "  elif (fitnessValue >= 1): record[-1] = round(fitnessValue, 3)\n",
        "  else: record[-1] = round(fitnessValue, 4)\n",
        "\n",
        "  del model, history, aug\n",
        "  gc.collect()\n",
        "\n",
        "  return fitnessValue, copy.copy(record)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-01-28T18:14:54.744654Z",
          "start_time": "2021-01-28T18:14:54.714646Z"
        },
        "code_folding": [
          0
        ],
        "hidden": true,
        "id": "qogO9pZ7x6GK"
      },
      "source": [
        "class PopulationBasedOptimizer(object):\n",
        "  def __init__(self,\n",
        "         fitnessFunction,\n",
        "         currentState,\n",
        "         lowerBound=0.0,\n",
        "         upperBound=1.0):\n",
        "    self.fitnessFunction = fitnessFunction\n",
        "    self.currentState = currentState\n",
        "    self.lowerBound = lowerBound\n",
        "    self.upperBound = upperBound\n",
        "\n",
        "    self.population = []\n",
        "    self.populationWithScores = []\n",
        "    self.currentIteration = 0\n",
        "\n",
        "  def GetPopulation(self):\n",
        "    return self.population.copy()\n",
        "\n",
        "  def GetPopulationWithScores(self):\n",
        "    return self.populationWithScores\n",
        "\n",
        "  def InitPopulation(self):\n",
        "    if (isinstance(self.currentState[\"DIM\"], int)):\n",
        "      R = self.currentState[\"DIM\"]\n",
        "    else:\n",
        "      R = len(self.currentState[\"DIM\"])\n",
        "    if (not isinstance(self.lowerBound, list)):\n",
        "      lb = [self.lowerBound for _ in range(R)]\n",
        "    if (not isinstance(self.upperBound, list)):\n",
        "      ub = [self.upperBound for _ in range(R)]\n",
        "    lb = np.asarray(lb)\n",
        "    ub = np.asarray(ub)\n",
        "\n",
        "    size = (self.currentState[\"POPULATION_SIZE\"], R)\n",
        "    uniformRandom = np.random.uniform(0, 1, size)\n",
        "    clippedUniformRandom = [x * (ub - lb) + lb for x in uniformRandom]\n",
        "    self.population = np.round(np.asarray(clippedUniformRandom), 3)\n",
        "\n",
        "  def CalculateFitnessScores(self):\n",
        "    populationWithFitnessValues = []\n",
        "    population = self.GetPopulation()\n",
        "    for j, solution in enumerate(population):\n",
        "      fitnessScore, record = self.fitnessFunction(\n",
        "        self.currentIteration, solution, self.currentState)\n",
        "      populationWithFitnessValues.append(\n",
        "        [solution, fitnessScore, record])\n",
        "    populationWithFitnessValues = sorted(populationWithFitnessValues,\n",
        "                       key=lambda s: s[1],\n",
        "                       reverse=True)\n",
        "    self.populationWithScores = populationWithFitnessValues\n",
        "\n",
        "  def Run(self):\n",
        "    if (self.currentState[\"SKIP\"] == 0\n",
        "        and self.currentState[\"POPULATION\"] is None):\n",
        "      self.InitPopulation()\n",
        "    else:\n",
        "      self.population = self.currentState[\"POPULATION\"]\n",
        "\n",
        "    for i in range(self.currentState[\"SKIP\"], self.currentState[\"ITERS\"]):\n",
        "      self.currentIteration = i + 1\n",
        "      self.CalculateFitnessScores()\n",
        "      self.LogHistory()\n",
        "      self.UpdatePopulation()\n",
        "      self.UpdateConfigurations()\n",
        "\n",
        "  def LogHistory(self):\n",
        "    for j, solution in enumerate(self.GetPopulationWithScores()):\n",
        "      mappedSolution = MapSolutionForCNN(self.currentState, solution[0])\n",
        "\n",
        "    bestSolution = self.GetPopulationWithScores()[0]\n",
        "    mappedBestSolution = MapSolutionAsString(self.currentState,\n",
        "                         bestSolution[0])\n",
        "    mappedBestSolution.extend(bestSolution[2])\n",
        "\n",
        "  def UpdateConfigurations(self):\n",
        "    self.currentState[\"SKIP\"] = self.currentIteration\n",
        "    self.currentState[\"POPULATION\"] = self.GetPopulation().copy()\n",
        "    self.StoreWorkStateNow()\n",
        "\n",
        "  def StoreWorkStateNow(self):\n",
        "    StoreWorkState(self.currentState, self.currentState[\"STATE_PICKLE\"])\n",
        "\n",
        "  @abstractmethod\n",
        "  def UpdatePopulation(self):\n",
        "    raise NotImplementedError(\n",
        "      \"UpdatePopulation function must be implemented.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-01-28T18:14:54.774906Z",
          "start_time": "2021-01-28T18:14:54.747628Z"
        },
        "code_folding": [
          0
        ],
        "hidden": true,
        "id": "Ownc10lKc02R"
      },
      "source": [
        "class GeneticAlgorithmOptimizer(PopulationBasedOptimizer):\n",
        "  def UpdatePopulation(self):\n",
        "    scores = self.GetPopulationWithScores()\n",
        "    mappedSolutions = []\n",
        "    for j, temp in enumerate(scores):\n",
        "      mappedSolution = MapSolutionForCNN(self.currentState, temp[0])\n",
        "      mappedSolutions.append(mappedSolution)\n",
        "\n",
        "    Lc = len(scores)\n",
        "    individuals = int(self.currentState[\"POPULATION_SIZE\"] / 2.0)\n",
        "    if (self.currentState[\"POPULATION_SIZE\"] % 2 != 0): individuals += 1\n",
        "    newPopulation = scores[:individuals].copy()\n",
        "    newPopulation = [e[0].copy() for e in newPopulation]\n",
        "\n",
        "    restCount = Lc - len(newPopulation)\n",
        "    permutations = list(\n",
        "      itertools.permutations(range(len(newPopulation)), 2)) * 3\n",
        "    random.shuffle(permutations)\n",
        "    if (isinstance(self.currentState[\"DIM\"], int)):\n",
        "      dim = self.currentState[\"DIM\"]\n",
        "    else:\n",
        "      dim = len(self.currentState[\"DIM\"])\n",
        "    halfDim = int(dim / 2)\n",
        "    cnt = 0\n",
        "\n",
        "    while cnt < restCount:\n",
        "      if (len(permutations) <= 0):\n",
        "        permutations = list(\n",
        "          itertools.permutations(range(len(newPopulation)), 2)) * 3\n",
        "        random.shuffle(permutations)\n",
        "      i, j = permutations.pop()\n",
        "\n",
        "      newSolution = []\n",
        "      newSolution.extend(newPopulation[i][:halfDim].copy())\n",
        "      newSolution.extend(newPopulation[j][halfDim:].copy())\n",
        "\n",
        "      if (np.random.random() >= 0.5):\n",
        "        randomIndex = np.random.randint(0, dim)\n",
        "        uniformRandom = np.random.uniform(0, 1)\n",
        "        delta = self.upperBound - self.lowerBound\n",
        "        clippedUniformRandom = uniformRandom * delta + self.lowerBound\n",
        "        newSolution[randomIndex] = clippedUniformRandom\n",
        "\n",
        "      newSolution = np.round(newSolution, 3)\n",
        "\n",
        "      mappedSolution = MapSolutionForCNN(self.currentState, newSolution)\n",
        "      if (mappedSolution not in mappedSolutions):\n",
        "        newPopulation.append(newSolution)\n",
        "        cnt += 1\n",
        "      else:\n",
        "        continue\n",
        "    random.shuffle(newPopulation)\n",
        "    self.population = np.round(np.asarray(newPopulation), 3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-01-28T18:14:54.867855Z",
          "start_time": "2021-01-28T18:14:54.822881Z"
        },
        "id": "GY_GQGWXc4w8"
      },
      "source": [
        "OWNER = \"H.M.B\"     \n",
        "PBO   = \"GA\"        \n",
        "USE_TF              = True   \n",
        "MODEL               = \"VGG16\"      \n",
        "DATASET_PICKLE_FILE = \"PICKLE_NAME_HERE\"\n",
        "PICKELS_BASE_DIR    = \"Pickels\" \n",
        "RESULTS_BASE_DIR    = \"Results\" \n",
        "IMAGE_SHAPE         = (64, 64, 3)        \n",
        "CATEGORIES          = (\"Normal\", \"Pneumonia-Viral\", \"Pneumonia-Bacterial\", \"COVID-19\")\n",
        "ITERS               = 15      \n",
        "EPOCHS              = 32      \n",
        "POPULATION_SIZE     = 10     \n",
        "DIM                 = 4\n",
        "SKIP                = 0 \n",
        "POPULATION          = None    \n",
        "IS_NEW              = False   \n",
        "TRAIN_RATIO         = 0.90    \n",
        "DROPOUT_RANGE       = [0, 6]\n",
        "OUTPUT_ACTIVATION   = \"softmax\"\n",
        "PRETRAINED_WEIGHTS  = \"imagenet\"\n",
        "BATCH_SIZES         = [32, 64, 32, 64, 32, 64, 32, 64, 32, 64, 32, 64]\n",
        "LEARN_RATIOS        = [0, 5, 10, 15, 20, 25, 30, 35, 40, 45, 50, 55, 60, 65, 70, 75, 80, 85, 90, 100]\n",
        "REGULARIZERS        = [\"l1_1e-2\", \"l1_1e-3\", \"l1_1e-4\", \"l1_1e-5\", \"l2_1e-2\", \"l2_1e-3\", \"l2_1e-4\", \"l2_1e-5\"]\n",
        "OPTIMIZERS          = [\"adam\", \"nadam\", \"adagrad\", \"adadelta\", \"adamax\", \"rmsprop\", \"sgd\", \"ftrl\"]\n",
        "HIDDEN_ACTIVATIONS  = [\"relu\", \"tanh\", \"elu\", \"selu\", \"exponential\", \"prelu\", \"leakyrelu\"]\n",
        "WEIGHT_INITIALIZERS = [\n",
        "  \"glorot_normal\", \"glorot_uniform\", \"lecun_normal\",\n",
        "  \"lecun_uniform\", \"he_normal\", \"he_uniform\",\n",
        "  \"random_normal\", \"random_uniform\", \"truncated_normal\"\n",
        "]\n",
        "AUGMENTATION_CONFIG = {\n",
        "  \"rotation_range\": 15,\n",
        "  \"width_shift_range\": 0.15,\n",
        "  \"height_shift_range\": 0.15,\n",
        "  \"shear_range\": 0.20,\n",
        "  \"zoom_range\": 0.20,\n",
        "  \"horizontal_flip\": True,\n",
        "  \"vertical_flip\": False,\n",
        "  \"fill_mode\": 'nearest'\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-01-28T18:14:54.914829Z",
          "start_time": "2021-01-28T18:14:54.885845Z"
        },
        "hidden": true,
        "id": "g_QPtGMnLnkO"
      },
      "source": [
        "RESULTS_DIR = os.path.join(BASE_DIR, RESULTS_BASE_DIR)\n",
        "DATASET_PICKLE = os.path.join(BASE_DIR, PICKELS_BASE_DIR, DATASET_PICKLE_FILE)\n",
        "OWNER_DIR = os.path.join(RESULTS_DIR, OWNER)\n",
        "if (not os.path.exists(OWNER_DIR)): os.mkdir(OWNER_DIR)\n",
        "HDF5_RESULTS_DIR = os.path.join(OWNER_DIR, f\"Models-{OWNER}\")\n",
        "FIGURES_RESULTS_DIR = os.path.join(OWNER_DIR, f\"Figures-{OWNER}\")\n",
        "HISTORY_RESULTS_DIR = os.path.join(OWNER_DIR, f\"History-{OWNER}\")\n",
        "STATE_PICKLE = os.path.join(OWNER_DIR, f\"State-{OWNER}.p\")\n",
        "LOGGER_FILE = os.path.join(OWNER_DIR, f\"Logger-{OWNER}.txt\")\n",
        "BEST_FILE = os.path.join(RESULTS_DIR, f\"Best-{OWNER}.csv\")\n",
        "SPLIT_DATASET_PICKLE = os.path.join(BASE_DIR, PICKELS_BASE_DIR,\n",
        "                  f\"Split-{DATASET_PICKLE_FILE}\")\n",
        "if (not os.path.exists(HDF5_RESULTS_DIR)): os.mkdir(HDF5_RESULTS_DIR)\n",
        "if (not os.path.exists(FIGURES_RESULTS_DIR)): os.mkdir(FIGURES_RESULTS_DIR)\n",
        "if (not os.path.exists(HISTORY_RESULTS_DIR)): os.mkdir(HISTORY_RESULTS_DIR)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-01-28T18:14:55.085732Z",
          "start_time": "2021-01-28T18:14:54.916827Z"
        },
        "hidden": true,
        "id": "jVVgE8Kbc4w_",
        "scrolled": true
      },
      "source": [
        "currentState = HandleCurrentState(IS_NEW, STATE_PICKLE, LOGGER_FILE)\n",
        "Q = LoadCreateSplitFile(currentState[\"DATASET_PICKLE\"],\n",
        "            currentState[\"SPLIT_DATASET_PICKLE\"],\n",
        "            len(currentState[\"CATEGORIES\"]),\n",
        "            currentState[\"TRAIN_RATIO\"], currentState[\"DEBUG\"])\n",
        "[Xtrain, Xvalidation, Xtest, Ytrain, Yvalidation, Ytest] = Q"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "start_time": "2021-01-28T18:14:54.217Z"
        },
        "id": "erfe6fhvc02J",
        "scrolled": true
      },
      "source": [
        "gao = GeneticAlgorithmOptimizer(FitnessFunction, currentState, lowerBound=0.0, upperBound=1.0)\n",
        "gao.Run()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}